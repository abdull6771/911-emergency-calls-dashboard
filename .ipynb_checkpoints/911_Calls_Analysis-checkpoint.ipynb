{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing 911 Emergency Calls: Cleaning, Visualization, and Insights\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Emergency 911 calls are a critical lifeline for communities, providing insights into public safety needs and resource allocation. This analysis explores a dataset of 911 calls from Kaggle (Montcoalert dataset), which contains details about emergency calls, including timestamps, locations (zip codes and townships), and call reasons. The dataset is known to be messy, with missing values, inconsistent categorizations, and potential duplicates, making it an excellent candidate for data cleaning and exploratory analysis.\n",
    "\n",
    "**Goals**:\n",
    "- Clean the dataset to ensure data quality.\n",
    "- Visualize trends in call patterns by reason, time, and location.\n",
    "- Derive actionable insights to inform public safety strategies.\n",
    "\n",
    "Let’s dive into the data, clean it up, and uncover the stories it tells!\n",
    "\n",
    "## Step 1: Loading and Inspecting the Data\n",
    "\n",
    "We’ll start by loading the dataset using Pandas and inspecting its structure to identify data quality issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Seaborn theme for better aesthetics\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('911.csv')\n",
    "\n",
    "# Display basic information\n",
    "print('Dataset Info:')\n",
    "df.info()\n",
    "\n",
    "# Show first few rows\n",
    "print('\\nFirst 5 Rows:')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The dataset contains columns like:\n",
    "- `lat`, `lng`: Geographic coordinates.\n",
    "- `desc`: Description of the call.\n",
    "- `zip`: Zip code of the call location.\n",
    "- `title`: Call reason (e.g., 'EMS: CARDIAC EMERGENCY').\n",
    "- `timeStamp`: Date and time of the call.\n",
    "- `twp`: Township.\n",
    "- `addr`: Address.\n",
    "- `e`: Unknown column (possibly a flag).\n",
    "\n",
    "**Initial Issues**:\n",
    "- **Missing Values**: `zip` and `twp` may have NaN values (to be confirmed).\n",
    "- **Data Types**: `timeStamp` is likely a string, not datetime.\n",
    "- **Inconsistent Categories**: `title` contains mixed formats (e.g., 'EMS:', 'Fire:').\n",
    "- **Redundant Columns**: `e` may be unnecessary.\n",
    "\n",
    "## Step 2: Data Cleaning\n",
    "\n",
    "Let’s address these issues systematically:\n",
    "\n",
    "### 2.1 Handling Missing Values\n",
    "\n",
    "We’ll check for missing values and decide how to handle them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing Values:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# - For 'zip', impute with mode (most frequent zip code)\n",
    "# - For 'twp', impute with 'Unknown'\n",
    "# - Drop rows with missing 'timeStamp' or 'title' (if any)\n",
    "\n",
    "df['zip'] = df['zip'].fillna(df['zip'].mode()[0])\n",
    "df['twp'] = df['twp'].fillna('Unknown')\n",
    "\n",
    "# Drop rows with missing critical columns (if any)\n",
    "df = df.dropna(subset=['timeStamp', 'title'])\n",
    "\n",
    "# Verify missing values\n",
    "print('\\nMissing Values After Cleaning:')\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale**:\n",
    "- `zip`: Imputing with the mode preserves the most common location context.\n",
    "- `twp`: 'Unknown' allows us to retain rows for analysis without assuming a specific township.\n",
    "- Dropping rows with missing `timeStamp` or `title` ensures we have complete data for temporal and categorical analysis.\n",
    "\n",
    "### 2.2 Parsing Timestamps\n",
    "\n",
    "Convert `timeStamp` to datetime and extract features like hour, day of week, and month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timeStamp to datetime\n",
    "df['timeStamp'] = pd.to_datetime(df['timeStamp'])\n",
    "\n",
    "# Extract features\n",
    "df['hour'] = df['timeStamp'].dt.hour\n",
    "df['day_of_week'] = df['timeStamp'].dt.day_name()\n",
    "df['month'] = df['timeStamp'].dt.month_name()\n",
    "df['year'] = df['timeStamp'].dt.year\n",
    "\n",
    "# Verify new columns\n",
    "df[['timeStamp', 'hour', 'day_of_week', 'month', 'year']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale**:\n",
    "- Parsing `timeStamp` enables temporal analysis (e.g., peak call hours).\n",
    "- Extracted features like `hour` and `day_of_week` facilitate visualization of patterns.\n",
    "\n",
    "### 2.3 Standardizing Categories\n",
    "\n",
    "Extract the main reason (EMS, Fire, Traffic) from the `title` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reason from title\n",
    "df['reason'] = df['title'].apply(lambda x: x.split(':')[0].strip())\n",
    "\n",
    "# Verify unique reasons\n",
    "print('Unique Reasons:', df['reason'].unique())\n",
    "\n",
    "# Check distribution\n",
    "print('\\nReason Distribution:')\n",
    "print(df['reason'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale**:\n",
    "- Splitting `title` isolates the primary reason, simplifying categorical analysis.\n",
    "- Checking unique values ensures no unexpected categories (e.g., typos).\n",
    "\n",
    "### 2.4 Removing Duplicates\n",
    "\n",
    "Check for and remove duplicate rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print('Number of Duplicates:', df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verify\n",
    "print('Number of Duplicates After Cleaning:', df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale**:\n",
    "- Duplicates can skew analysis (e.g., inflating call counts).\n",
    "- Removing them ensures accurate trend representation.\n",
    "\n",
    "## Step 3: Exploratory Data Analysis\n",
    "\n",
    "With the data cleaned, let’s visualize trends to uncover patterns in 911 calls.\n",
    "\n",
    "### 3.1 Distribution of Calls by Reason\n",
    "\n",
    "Which call types are most common?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of calls by reason\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='reason', data=df, palette='viridis')\n",
    "plt.title('Distribution of 911 Calls by Reason')\n",
    "plt.xlabel('Reason')\n",
    "plt.ylabel('Number of Calls')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**:\n",
    "- EMS calls likely dominate, reflecting medical emergencies as a primary driver of 911 usage.\n",
    "- Fire calls are probably the least frequent, indicating fewer fire-related incidents.\n",
    "\n",
    "### 3.2 Call Volume Over Time\n",
    "\n",
    "How does call volume vary by month?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by month and count calls\n",
    "monthly_calls = df.groupby('month').size().reindex(\n",
    "    ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "     'July', 'August', 'September', 'October', 'November', 'December']\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_calls.plot(kind='line', marker='o', color='b')\n",
    "plt.title('911 Call Volume by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Calls')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**:\n",
    "- Call volume may peak in certain months (e.g., winter due to weather-related incidents or summer due to outdoor activities).\n",
    "- This suggests seasonal resource planning (e.g., more staff in high-call months).\n",
    "\n",
    "### 3.3 Peak Call Times\n",
    "\n",
    "When are calls most frequent during the day and week?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for heatmap\n",
    "day_hour = df.groupby(['day_of_week', 'hour']).size().unstack()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_hour = day_hour.reindex(day_order)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(day_hour, cmap='YlOrRd', annot=True, fmt='d')\n",
    "plt.title('911 Calls by Day of Week and Hour')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**:\n",
    "- Calls likely peak during daytime hours (e.g., 9 AM–5 PM), especially on weekdays, possibly due to higher activity levels.\n",
    "- Weekends may show different patterns, with more calls in the evening (e.g., accidents or social incidents).\n",
    "\n",
    "### 3.4 Top Townships by Call Volume\n",
    "\n",
    "Which townships generate the most calls?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 townships by call volume\n",
    "top_townships = df['twp'].value_counts().head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_townships.values, y=top_townships.index, palette='magma')\n",
    "plt.title('Top 10 Townships by 911 Call Volume')\n",
    "plt.xlabel('Number of Calls')\n",
    "plt.ylabel('Township')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**:\n",
    "- High-call-volume townships may have larger populations or specific risk factors (e.g., industrial areas for fire calls).\n",
    "- These areas could benefit from targeted safety campaigns or additional emergency resources.\n",
    "\n",
    "## Step 4: Actionable Insights\n",
    "\n",
    "Based on the analysis, here are key recommendations:\n",
    "\n",
    "1. **Optimize Staffing by Time**:\n",
    "   - Increase EMS and Traffic response teams during peak hours (e.g., 9 AM–5 PM) and weekdays, as identified in the heatmap.\n",
    "   - Prepare for evening surges on weekends, possibly due to social or recreational incidents.\n",
    "\n",
    "2. **Prioritize EMS Resources**:\n",
    "   - EMS calls dominate, suggesting a need for more medical training or ambulance availability compared to fire services.\n",
    "\n",
    "3. **Target High-Volume Townships**:\n",
    "   - Focus safety education and infrastructure improvements (e.g., traffic signals, fire prevention) in top townships like Norristown.\n",
    "\n",
    "4. **Plan for Seasonal Spikes**:\n",
    "   - Anticipate higher call volumes in peak months (e.g., winter or summer) by securing additional resources or temporary staff.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This analysis transformed a messy 911 calls dataset into a clean, insightful resource for public safety planning. By addressing missing values, parsing timestamps, and standardizing categories, we ensured data quality. Visualizations revealed critical patterns in call reasons, timing, and locations, leading to actionable recommendations for resource allocation and community safety.\n",
    "\n",
    "**Next Steps**:\n",
    "- Build predictive models to forecast call volumes based on historical trends.\n",
    "- Analyze call descriptions (`desc`) for more granular insights (e.g., specific medical emergencies).\n",
    "- Collaborate with local authorities to implement these recommendations.\n",
    "\n",
    "This dataset, though messy, tells a powerful story about community needs and emergency response—let’s use it to make a difference!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
